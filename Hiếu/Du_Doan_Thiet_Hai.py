"""
Dá»± Ä‘oÃ¡n thiá»‡t háº¡i vá» ngÆ°á»i do tháº£m há»a gÃ¢y ra
Input: Quá»‘c gia, tháº£m há»a, má»©c Ä‘á»™ nghiÃªm trá»ng, thiá»‡t háº¡i kinh táº¿, 
       thá»i gian pháº£n á»©ng, hiá»‡u quáº£ pháº£n á»©ng, kinh Ä‘á»™, vÄ© Ä‘á»™
Output: Sá»‘ ngÆ°á»i bá»‹ cháº¿t do tháº£m há»a
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
import warnings

warnings.filterwarnings('ignore')


class DisasterCasualtyPredictor:
    """MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sá»‘ ngÆ°á»i bá»‹ cháº¿t do tháº£m há»a"""
    
    def __init__(self, csv_path: str):
        """
        Khá»Ÿi táº¡o mÃ´ hÃ¬nh
        
        Parameters
        ----------
        csv_path : str
            ÄÆ°á»ng dáº«n file CSV chá»©a dá»¯ liá»‡u huáº¥n luyá»‡n
        """
        self.csv_path = csv_path
        self.df = None
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.feature_columns = None
        
    def load_data(self):
        """Load vÃ  xá»­ lÃ½ dá»¯ liá»‡u tá»« CSV"""
        print("ğŸ“Š Äang táº£i dá»¯ liá»‡u...")
        self.df = pd.read_csv(self.csv_path)
        
        print(f"âœ… Táº£i thÃ nh cÃ´ng {len(self.df)} báº£n ghi")
        print(f"CÃ¡c cá»™t: {list(self.df.columns)}")
        print(f"\nThá»‘ng kÃª dá»¯ liá»‡u Casualties:")
        print(f"  Min: {self.df['casualties'].min():.0f}")
        print(f"  Max: {self.df['casualties'].max():.0f}")
        print(f"  Mean: {self.df['casualties'].mean():.0f}")
        print(f"  Median: {self.df['casualties'].median():.0f}")
        
        return self.df
    
    def prepare_features(self, df=None):
        """
        Chuáº©n bá»‹ features cho mÃ´ hÃ¬nh
        
        Parameters
        ----------
        df : pd.DataFrame, optional
            DataFrame Ä‘á»ƒ xá»­ lÃ½. Náº¿u None, dÃ¹ng self.df
            
        Returns
        -------
        X : np.ndarray
            Features Ä‘Ã£ xá»­ lÃ½
        y : np.ndarray
            Target (casualties)
        """
        if df is None:
            df = self.df.copy()
        else:
            df = df.copy()
        
        # XÃ³a cÃ¡c cá»™t khÃ´ng cáº§n thiáº¿t
        df = df.drop(columns=['date', 'aid_amount_usd', 'recovery_days', 'continent'], 
                     errors='ignore')
        
        # TÃ¡ch target
        y = df['casualties'].values
        
        # Features: quá»‘c gia, loáº¡i tháº£m há»a, má»©c Ä‘á»™, thiá»‡t háº¡i kinh táº¿, 
        #          thá»i gian pháº£n á»©ng, hiá»‡u quáº£ pháº£n á»©ng, kinh Ä‘á»™, vÄ© Ä‘á»™
        feature_cols = ['country', 'disaster_type', 'severity_index', 'economic_loss_usd',
                       'response_time_hours', 'response_efficiency_score', 
                       'latitude', 'longitude']
        
        X = df[feature_cols].copy()
        
        # Encode cÃ¡c cá»™t categorical
        for col in ['country', 'disaster_type']:
            if col not in self.label_encoders:
                self.label_encoders[col] = LabelEncoder()
                X[col] = self.label_encoders[col].fit_transform(X[col].astype(str))
            else:
                X[col] = self.label_encoders[col].transform(X[col].astype(str))
        
        self.feature_columns = feature_cols
        
        return X.values, y
    
    def train(self, test_size=0.2, random_state=42):
        """
        Huáº¥n luyá»‡n mÃ´ hÃ¬nh
        
        Parameters
        ----------
        test_size : float
            Tá»· lá»‡ chia test set
        random_state : int
            Random seed
        """
        print("\nğŸ”§ Äang chuáº©n bá»‹ dá»¯ liá»‡u...")
        X, y = self.prepare_features()
        
        # Chia dá»¯ liá»‡u
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        print(f"   Train size: {len(X_train)}, Test size: {len(X_test)}")
        
        # Chuáº©n hÃ³a features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh Gradient Boosting
        print("ğŸš€ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh Gradient Boosting...")
        self.model = GradientBoostingRegressor(
            n_estimators=200,
            learning_rate=0.1,
            max_depth=5,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=random_state,
            verbose=0
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
        y_pred_train = self.model.predict(X_train_scaled)
        y_pred_test = self.model.predict(X_test_scaled)
        
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        train_mae = mean_absolute_error(y_train, y_pred_train)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        
        print(f"\nğŸ“ˆ Káº¿t quáº£ Ä‘Ã¡nh giÃ¡:")
        print(f"  Train RÂ² Score: {train_r2:.4f}")
        print(f"  Test RÂ² Score: {test_r2:.4f}")
        print(f"  Train RMSE: {train_rmse:.2f}")
        print(f"  Test RMSE: {test_rmse:.2f}")
        print(f"  Train MAE: {train_mae:.2f}")
        print(f"  Test MAE: {test_mae:.2f}")
        
        # Feature importance
        print(f"\nâ­ Táº§m quan trá»ng cá»§a features:")
        feature_importance = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        for idx, row in feature_importance.iterrows():
            print(f"  {row['feature']:30s}: {row['importance']:.4f}")
        
        return {
            'train_r2': train_r2,
            'test_r2': test_r2,
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'train_mae': train_mae,
            'test_mae': test_mae
        }
    
    def predict(self, country: str, disaster_type: str, severity_index: float,
                economic_loss_usd: float, response_time_hours: float,
                response_efficiency_score: float, latitude: float, 
                longitude: float) -> float:
        """
        Dá»± Ä‘oÃ¡n sá»‘ ngÆ°á»i bá»‹ cháº¿t
        
        Parameters
        ----------
        country : str
            Quá»‘c gia
        disaster_type : str
            Loáº¡i tháº£m há»a
        severity_index : float
            Má»©c Ä‘á»™ nghiÃªm trá»ng (0-10)
        economic_loss_usd : float
            Thiá»‡t háº¡i kinh táº¿ (USD)
        response_time_hours : float
            Thá»i gian pháº£n á»©ng (giá»)
        response_efficiency_score : float
            Äiá»ƒm hiá»‡u quáº£ pháº£n á»©ng (0-100)
        latitude : float
            VÄ© Ä‘á»™
        longitude : float
            Kinh Ä‘á»™
            
        Returns
        -------
        float
            Dá»± Ä‘oÃ¡n sá»‘ ngÆ°á»i bá»‹ cháº¿t
        """
        if self.model is None:
            raise ValueError("MÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Gá»i train() trÆ°á»›c.")
        
        # Chuáº©n bá»‹ input
        input_data = pd.DataFrame({
            'country': [country],
            'disaster_type': [disaster_type],
            'severity_index': [severity_index],
            'economic_loss_usd': [economic_loss_usd],
            'response_time_hours': [response_time_hours],
            'response_efficiency_score': [response_efficiency_score],
            'latitude': [latitude],
            'longitude': [longitude]
        })
        
        # Encode categorical features
        for col in ['country', 'disaster_type']:
            try:
                input_data[col] = self.label_encoders[col].transform(
                    input_data[col].astype(str)
                )
            except ValueError:
                print(f"âš ï¸  {col} '{input_data[col].values[0]}' khÃ´ng trong dá»¯ liá»‡u huáº¥n luyá»‡n")
                input_data[col] = 0
        
        # Chuáº©n hÃ³a
        input_scaled = self.scaler.transform(input_data)
        
        # Dá»± Ä‘oÃ¡n
        prediction = self.model.predict(input_scaled)[0]
        
        return max(0, prediction)
    
    def save_model(self, filepath: str):
        """LÆ°u mÃ´ hÃ¬nh"""
        joblib.dump({
            'model': self.model,
            'scaler': self.scaler,
            'label_encoders': self.label_encoders,
            'feature_columns': self.feature_columns
        }, filepath)
        print(f"âœ… MÃ´ hÃ¬nh Ä‘Ã£ lÆ°u táº¡i {filepath}")
    
    def load_model(self, filepath: str):
        """Load mÃ´ hÃ¬nh tá»« file"""
        data = joblib.load(filepath)
        self.model = data['model']
        self.scaler = data['scaler']
        self.label_encoders = data['label_encoders']
        self.feature_columns = data['feature_columns']
        print(f"âœ… MÃ´ hÃ¬nh Ä‘Ã£ load tá»« {filepath}")


def interactive_prediction(csv_path="du_lieu_sach.csv"):
    """Dá»± Ä‘oÃ¡n tÆ°Æ¡ng tÃ¡c tá»« input cá»§a ngÆ°á»i dÃ¹ng"""
    print("\n" + "="*70)
    print("ğŸ”® CHáº¾ Äá»˜ Dá»° ÄOÃN TÆ¯Æ NG TÃC")
    print("="*70)
    
    predictor = DisasterCasualtyPredictor(csv_path)
    predictor.load_data()
    predictor.train()
    
    # Láº¥y danh sÃ¡ch quá»‘c gia vÃ  tháº£m há»a tá»« dá»¯ liá»‡u
    countries = sorted(predictor.df['country'].unique())
    disaster_types = sorted(predictor.df['disaster_type'].unique())
    
    print(f"\nğŸ“ CÃ¡c quá»‘c gia trong dá»¯ liá»‡u:")
    for i, country in enumerate(countries, 1):
        print(f"   {i}. {country}")
    
    print(f"\nâš ï¸  CÃ¡c loáº¡i tháº£m há»a:")
    for i, dtype in enumerate(disaster_types, 1):
        print(f"   {i}. {dtype}")
    
    while True:
        print("\n" + "-"*70)
        
        try:
            country = input("Nháº­p quá»‘c gia (hoáº·c 'quit' Ä‘á»ƒ thoÃ¡t): ").strip()
            if country.lower() == 'quit':
                break
            
            disaster_type = input("Nháº­p loáº¡i tháº£m há»a: ").strip()
            severity_index = float(input("Nháº­p má»©c Ä‘á»™ nghiÃªm trá»ng (0-10): "))
            economic_loss = float(input("Nháº­p thiá»‡t háº¡i kinh táº¿ (USD): "))
            response_time = float(input("Nháº­p thá»i gian pháº£n á»©ng (giá»): "))
            efficiency = float(input("Nháº­p hiá»‡u quáº£ pháº£n á»©ng (0-100): "))
            latitude = float(input("Nháº­p vÄ© Ä‘á»™: "))
            longitude = float(input("Nháº­p kinh Ä‘á»™: "))
            
            prediction = predictor.predict(
                country=country,
                disaster_type=disaster_type,
                severity_index=severity_index,
                economic_loss_usd=economic_loss,
                response_time_hours=response_time,
                response_efficiency_score=efficiency,
                latitude=latitude,
                longitude=longitude
            )
            
            print("\n" + "="*70)
            print(f"ğŸ“Š Káº¾T QUáº¢ Dá»° ÄOÃN")
            print("="*70)
            print(f"  ğŸŒ Quá»‘c gia: {country}")
            print(f"  âš ï¸  Tháº£m há»a: {disaster_type}")
            print(f"  ğŸ“Š Má»©c Ä‘á»™: {severity_index}/10")
            print(f"  ğŸ’° Thiá»‡t háº¡i kinh táº¿: ${economic_loss:,.0f}")
            print(f"  â±ï¸  Thá»i gian pháº£n á»©ng: {response_time} giá»")
            print(f"  â­ Hiá»‡u quáº£: {efficiency}/100")
            print(f"  ğŸ“ Vá»‹ trÃ­: ({latitude}, {longitude})")
            print("-"*70)
            print(f"ğŸ‘¥ Dá»° ÄOÃN Sá» NGÆ¯á»œI Bá»Š CHáº¾T: {prediction:.0f} ngÆ°á»i")
            print("="*70)
            
        except ValueError:
            print(f"âŒ Lá»—i: Vui lÃ²ng nháº­p dá»¯ liá»‡u há»£p lá»‡!")
        except Exception as e:
            print(f"âŒ Lá»—i: {str(e)}")


def test_predictions(csv_path="du_lieu_sach.csv"):
    """Test dá»± Ä‘oÃ¡n vá»›i má»™t sá»‘ trÆ°á»ng há»£p"""
    
    predictor = DisasterCasualtyPredictor(csv_path)
    
    # Load dá»¯ liá»‡u
    predictor.load_data()
    
    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    predictor.train()
    
    # LÆ°u mÃ´ hÃ¬nh
    predictor.save_model("disaster_casualty_model.pkl")
    
    # Test dá»± Ä‘oÃ¡n vá»›i má»™t sá»‘ trÆ°á»ng há»£p
    print("\n" + "="*70)
    print("ğŸ”® TEST Dá»° ÄOÃN Vá»šI CÃC TRÆ¯á»œNG Há»¢P MáºªU")
    print("="*70)
    
    test_cases = [
        {
            'country': 'India',
            'disaster_type': 'Earthquake',
            'severity_index': 8.0,
            'economic_loss_usd': 5000000,
            'response_time_hours': 12,
            'response_efficiency_score': 85,
            'latitude': 28.7,
            'longitude': 77.2,
            'description': 'Äá»™ng Ä‘áº¥t máº¡nh táº¡i áº¤n Äá»™'
        },
        {
            'country': 'Philippines',
            'disaster_type': 'Flood',
            'severity_index': 7.5,
            'economic_loss_usd': 3000000,
            'response_time_hours': 8,
            'response_efficiency_score': 90,
            'latitude': 14.5,
            'longitude': 121.0,
            'description': 'LÅ© lá»¥t á»Ÿ Philippines'
        },
        {
            'country': 'Brazil',
            'disaster_type': 'Wildfire',
            'severity_index': 6.5,
            'economic_loss_usd': 2000000,
            'response_time_hours': 16,
            'response_efficiency_score': 75,
            'latitude': -23.55,
            'longitude': -46.6,
            'description': 'ChÃ¡y rá»«ng á»Ÿ Brazil'
        },
        {
            'country': 'Japan',
            'disaster_type': 'Earthquake',
            'severity_index': 9.0,
            'economic_loss_usd': 8000000,
            'response_time_hours': 2,
            'response_efficiency_score': 95,
            'latitude': 35.6762,
            'longitude': 139.6503,
            'description': 'Äá»™ng Ä‘áº¥t cá»±c máº¡nh táº¡i Nháº­t Báº£n'
        },
        {
            'country': 'United States',
            'disaster_type': 'Hurricane',
            'severity_index': 8.5,
            'economic_loss_usd': 10000000,
            'response_time_hours': 6,
            'response_efficiency_score': 88,
            'latitude': 29.9511,
            'longitude': -90.2623,
            'description': 'BÃ£o táº¥n cÃ´ng New Orleans'
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        desc = case.pop('description')
        prediction = predictor.predict(**case)
        
        print(f"\nğŸ“ TrÆ°á»ng há»£p {i}: {desc}")
        print(f"   ğŸŒ Quá»‘c gia: {case['country']}")
        print(f"   âš ï¸  Tháº£m há»a: {case['disaster_type']}")
        print(f"   ğŸ“Š Má»©c Ä‘á»™: {case['severity_index']}/10")
        print(f"   ğŸ’° Thiá»‡t háº¡i: ${case['economic_loss_usd']:,.0f}")
        print(f"   â±ï¸  Thá»i gian pháº£n á»©ng: {case['response_time_hours']} giá»")
        print(f"   â­ Hiá»‡u quáº£: {case['response_efficiency_score']}/100")
        print(f"   ğŸ“ Vá»‹ trÃ­: ({case['latitude']}, {case['longitude']})")
        print(f"   ğŸ‘¥ Dá»° ÄOÃN Sá» NGÆ¯á»œI Bá»Š CHáº¾T: {prediction:.0f} ngÆ°á»i")


def main():
    """Main function"""
    
    print("\n" + "="*70)
    print("ğŸŒ Há»† THá»NG Dá»° ÄOÃN THIá»†T Háº I NGÆ¯á»œI DO THáº¢M Há»ŒA")
    print("="*70)
    print("\nChá»n cháº¿ Ä‘á»™:")
    print("1. Test vá»›i cÃ¡c trÆ°á»ng há»£p máº«u")
    print("2. Dá»± Ä‘oÃ¡n tÆ°Æ¡ng tÃ¡c (nháº­p dá»¯ liá»‡u tá»« bÃ n phÃ­m)")
    print("3. ThoÃ¡t")
    
    choice = input("\nNháº­p lá»±a chá»n (1/2/3): ").strip()
    
    if choice == '1':
        test_predictions()
    elif choice == '2':
        interactive_prediction()
    else:
        print("ğŸ‘‹ Táº¡m biá»‡t!")


if __name__ == "__main__":
    main()