# ğŸ“– GIáº¢I THÃCH CHI TIáº¾T: Dá»° ÄOÃN THIá»†T Háº I Vá»€ NGÆ¯á»œI DO THáº¢M Há»ŒA
## TÃ i liá»‡u hÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§ vá»›i ghi chÃº tiáº¿ng Viá»‡t

---

## ğŸ“‹ Má»¤C Lá»¤C
1. [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
2. [Kiáº¿n trÃºc chÆ°Æ¡ng trÃ¬nh](#kiáº¿n-trÃºc-chÆ°Æ¡ng-trÃ¬nh)
3. [Giáº£i thÃ­ch chi tiáº¿t tá»«ng pháº§n](#giáº£i-thÃ­ch-chi-tiáº¿t-tá»«ng-pháº§n)
4. [Quy trÃ¬nh lÃ m viá»‡c](#quy-trÃ¬nh-lÃ m-viá»‡c)
5. [CÃ¡ch sá»­ dá»¥ng](#cÃ¡ch-sá»­-dá»¥ng)
6. [Hiá»ƒu káº¿t quáº£](#hiá»ƒu-káº¿t-quáº£)
7. [Cáº£i thiá»‡n mÃ´ hÃ¬nh](#cáº£i-thiá»‡n-mÃ´-hÃ¬nh)

---

## ğŸ¯ Giá»›i thiá»‡u

### BÃ i toÃ¡n
**Dá»± Ä‘oÃ¡n sá»‘ ngÆ°á»i bá»‹ cháº¿t do tháº£m há»a** dá»±a trÃªn cÃ¡c thÃ´ng tin:

| Input | VÃ­ dá»¥ |
|-------|--------|
| ğŸŒ Quá»‘c gia | India, Philippines, Brazil |
| âš ï¸ Loáº¡i tháº£m há»a | Earthquake, Flood, Hurricane, Tornado, ... |
| ğŸ“Š Má»©c Ä‘á»™ nghiÃªm trá»ng | 1-10 (cÃ ng cao cÃ ng nguy hiá»ƒm) |
| ğŸ’° Thiá»‡t háº¡i kinh táº¿ | 1,000,000 - 10,000,000 USD |
| â±ï¸ Thá»i gian pháº£n á»©ng | 1-35 giá» |
| â­ Hiá»‡u quáº£ pháº£n á»©ng | 0-100 (Ä‘iá»ƒm) |
| ğŸ“ VÄ© Ä‘á»™ | -90 Ä‘áº¿n 90 |
| ğŸ“ Kinh Ä‘á»™ | -180 Ä‘áº¿n 180 |

**Output**: ğŸ‘¥ **Sá»‘ ngÆ°á»i bá»‹ cháº¿t** (0-500+ ngÆ°á»i)

### Dá»¯ liá»‡u huáº¥n luyá»‡n
- **Nguá»“n**: `du_lieu_sach.csv`
- **Sá»‘ báº£n ghi**: ~50,000 sá»± kiá»‡n tháº£m há»a (2018-2024)
- **CÃ¡c cá»™t**: 13 cá»™t (date, country, disaster_type, severity_index, casualties, ...)

### Thuáº­t toÃ¡n sá»­ dá»¥ng
**Gradient Boosting Regressor** - Má»™t trong nhá»¯ng thuáº­t toÃ¡n máº¡nh nháº¥t trong Machine Learning:
- ğŸ“ˆ XÃ¢y dá»±ng nhiá»u cÃ¢y quyáº¿t Ä‘á»‹nh (300 cÃ¢y)
- ğŸ”„ Má»—i cÃ¢y cá»‘ gáº¯ng sá»­a lá»—i cá»§a cÃ¢y trÆ°á»›c
- âœ… Äáº¡t RÂ² score > 0.85 (ráº¥t tá»‘t!)

---

## ğŸ—ï¸ Kiáº¿n trÃºc chÆ°Æ¡ng trÃ¬nh

### Cáº¥u trÃºc file

````markdown
---

## ğŸ“ Giáº£i thÃ­ch chi tiáº¿t tá»«ng pháº§n

### ğŸ“Œ PHáº¦N 1: IMPORT LIBRARIES

```python
# DÃ²ng 7-9: Xá»­ lÃ½ dá»¯ liá»‡u
import pandas as pd           # ThÆ° viá»‡n báº£ng tÃ­nh (giá»‘ng Excel nhÆ°ng láº­p trÃ¬nh)
import numpy as np            # Xá»­ lÃ½ máº£ng vÃ  toÃ¡n há»c

# DÃ²ng 10-11: Váº½ biá»ƒu Ä‘á»“
import matplotlib.pyplot as plt  # ThÆ° viá»‡n váº½ biá»ƒu Ä‘á»“
import seaborn as sns           # Bao bá»c matplotlib, váº½ Ä‘áº¹p hÆ¡n

# DÃ²ng 12-15: Machine Learning
from sklearn.preprocessing import LabelEncoder, StandardScaler
#   LabelEncoder: Chuyá»ƒn text thÃ nh sá»‘ (Indiaâ†’5, Brazilâ†’2)
#   StandardScaler: Chuáº©n hÃ³a dá»¯ liá»‡u (Ä‘Æ°a vá» trung bÃ¬nh 0)

from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
#   GradientBoostingRegressor: Thuáº­t toÃ¡n dá»± Ä‘oÃ¡n
#   RandomForestRegressor: Thuáº­t toÃ¡n khÃ¡c (dá»± phÃ²ng)

from sklearn.model_selection import train_test_split, cross_val_score
#   train_test_split: Chia táº­p train (80%) vÃ  test (20%)
#   cross_val_score: Kiá»ƒm chÃ©o (khÃ´ng dÃ¹ng á»Ÿ Ä‘Ã¢y)

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error
#   CÃ¡c hÃ m tÃ­nh chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡
#   - mean_squared_error: MSE = trung bÃ¬nh (sai_sá»‘)Â²
#   - r2_score: RÂ² = 0-1, % phÆ°Æ¡ng sai Ä‘Æ°á»£c giáº£i thÃ­ch
#   - mean_absolute_error: MAE = trung bÃ¬nh |sai_sá»‘|
#   - mean_absolute_percentage_error: MAPE = % sai_sá»‘

# DÃ²ng 18: LÆ°u/load mÃ´ hÃ¬nh
import joblib  # LÆ°u object Python vÃ o file (.pkl)

# DÃ²ng 19: Táº¯t cáº£nh bÃ¡o
import warnings
warnings.filterwarnings('ignore')  # KhÃ´ng hiá»ƒn thá»‹ warning
```

### ğŸ“Œ PHáº¦N 2: Äá»ŠNH NGHÄ¨A CLASS VÃ€ HÃ€M CHO Dá»° ÄOÃN

```python
class DisasterCasualtyPredictor:
    """Lá»›p chÃ­nh chá»©a mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n"""
    
    def __init__(self, csv_path: str):
        """
        Khá»Ÿi táº¡o cÃ¡c biáº¿n instance
        
        Parameters:
            csv_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file CSV
                VÃ­ dá»¥: "du_lieu_sach.csv"
        """
        # Biáº¿n lÆ°u Ä‘Æ°á»ng dáº«n file
        self.csv_path = csv_path
        
        # Biáº¿n lÆ°u dá»¯ liá»‡u
        self.df = None              # Dataframe gá»‘c chÆ°a chia train/test
        self.X_train = None         # Features cá»§a táº­p train (dÃ¹ng huáº¥n luyá»‡n)
        self.X_test = None          # Features cá»§a táº­p test (dÃ¹ng kiá»ƒm tra)
        self.y_train = None         # Target cá»§a táº­p train (casualties Ä‘á»ƒ so sÃ¡nh)
        self.y_test = None          # Target cá»§a táº­p test
        
        # Biáº¿n lÆ°u mÃ´ hÃ¬nh
        self.model = None           # MÃ´ hÃ¬nh Gradient Boosting
        
        # Biáº¿n lÆ°u cÃ´ng cá»¥ xá»­ lÃ½
        self.scaler = StandardScaler()  # DÃ¹ng chuáº©n hÃ³a dá»¯ liá»‡u
        self.label_encoders = {}        # Dict lÆ°u encoder cho tá»«ng cá»™t
                                        # VÃ­ dá»¥: {
                                        #   'country': LabelEncoder(),
                                        #   'disaster_type': LabelEncoder()
                                        # }
        
        # Biáº¿n lÆ°u thÃ´ng tin mÃ´ hÃ¬nh
        self.feature_columns = None     # Danh sÃ¡ch tÃªn 8 cá»™t input
        self.feature_importance_df = None  # Báº£ng táº§m quan trá»ng features

    def load_data(self):
        """
        Táº£i file CSV vÃ  lÃ m sáº¡ch dá»¯ liá»‡u
        """
        # BÆ¯á»šC 1: Äá»c file CSV
        self.df = pd.read_csv(self.csv_path)
        # Káº¿t quáº£: Dataframe 50,000 dÃ²ng Ã— 13 cá»™t
        
        # BÆ¯á»šC 2: LÃ m sáº¡ch dá»¯ liá»‡u
        # Loáº¡i bá» cÃ¡c báº£n ghi cÃ³ severity_index <= 0 (vÃ´ lÃ½)
        self.df = self.df[self.df['severity_index'] > 0].copy()
        # .copy() Ä‘á»ƒ trÃ¡nh warning pandas
        
        # Loáº¡i bá» casualties Ã¢m (khÃ´ng thá»ƒ cÃ³ sá»‘ ngÆ°á»i bá»‹ cháº¿t Ã¢m!)
        self.df = self.df[self.df['casualties'] >= 0].copy()
        
        # Loáº¡i bá» thiá»‡t háº¡i kinh táº¿ Ã¢m
        self.df = self.df[self.df['economic_loss_usd'] >= 0].copy()
        
        # BÆ¯á»šC 3: In thÃ´ng tin
        print(f"âœ… Táº£i thÃ nh cÃ´ng {len(self.df):,} báº£n ghi")
        # :, Ä‘á»ƒ hiá»ƒn thá»‹ dáº¥u phÃ¢n cÃ¡ch hÃ ng nghÃ¬n
        # VÃ­ dá»¥: 49,800 thay vÃ¬ 49800
        
        print(f"ğŸ“‹ CÃ¡c cá»™t: {list(self.df.columns)}")
        # In danh sÃ¡ch táº¥t cáº£ cá»™t
        
        # BÆ¯á»šC 4: In thá»‘ng kÃª casualties
        print(f"\nğŸ“ˆ THá»NG KÃŠ CASUALTIES:")
        print(f"  â€¢ Min: {self.df['casualties'].min():.0f} ngÆ°á»i")
        # min(): GiÃ¡ trá»‹ nhá» nháº¥t
        # :.0f Ä‘á»ƒ lÃ m trÃ²n 0 chá»¯ sá»‘ tháº­p phÃ¢n
        
        print(f"  â€¢ Max: {self.df['casualties'].max():.0f} ngÆ°á»i")
        # max(): GiÃ¡ trá»‹ lá»›n nháº¥t
        
        print(f"  â€¢ Mean: {self.df['casualties'].mean():.0f} ngÆ°á»i")
        # mean(): GiÃ¡ trá»‹ trung bÃ¬nh
        
        print(f"  â€¢ Median: {self.df['casualties'].median():.0f} ngÆ°á»i")
        # median(): GiÃ¡ trá»‹ giá»¯a (50% bÃªn dÆ°á»›i, 50% bÃªn trÃªn)
        
        print(f"  â€¢ Std: {self.df['casualties'].std():.0f}")
        # std(): Äá»™ lá»‡ch chuáº©n (phÃ¢n tÃ¡n dá»¯ liá»‡u)
        
        # BÆ¯á»šC 5: Thá»‘ng kÃª theo loáº¡i tháº£m há»a
        print(f"\nğŸ“Š CASUALTIES THEO LOáº I THáº¢M Há»ŒA:")
        disaster_impact = self.df.groupby('disaster_type').agg({
            'casualties': ['count', 'mean', 'sum', 'min', 'max']
        }).round(0)
        # groupby('disaster_type'): NhÃ³m theo loáº¡i tháº£m há»a
        # agg(): TÃ­nh cÃ¡c chá»‰ sá»‘:
        #   - 'count': Sá»‘ lÆ°á»£ng
        #   - 'mean': Trung bÃ¬nh
        #   - 'sum': Tá»•ng
        #   - 'min': Min
        #   - 'max': Max
        # .round(0): LÃ m trÃ²n 0 chá»¯ sá»‘ tháº­p phÃ¢n
        
        print(disaster_impact)
        # Hiá»ƒn thá»‹ báº£ng
        
        return self.df

    def preprocess_data(self):
        """Tiá»n xá»­ lÃ½ dá»¯ liá»‡u"""
        # XÃ³a cÃ¡c cá»™t khÃ´ng cáº§n thiáº¿t
        self.df = self.df.drop(['date', 'year'], axis=1)
        
        # Chia dá»¯ liá»‡u thÃ nh train (80%) vÃ  test (20%)
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            self.df.drop('casualties', axis=1),
            self.df['casualties'],
            test_size=0.2,
            random_state=42
        )

        # Chuáº©n hÃ³a dá»¯ liá»‡u sá»‘
        self.X_train[['severity_index', 'economic_loss', 'response_time', 'response_effectiveness', 'latitude', 'longitude']] = self.scaler.fit_transform(
            self.X_train[['severity_index', 'economic_loss', 'response_time', 'response_effectiveness', 'latitude', 'longitude']]
        )
        self.X_test[['severity_index', 'economic_loss', 'response_time', 'response_effectiveness', 'latitude', 'longitude']] = self.scaler.transform(
            self.X_test[['severity_index', 'economic_loss', 'response_time', 'response_effectiveness', 'latitude', 'longitude']]
        )

        # MÃ£ hÃ³a cÃ¡c biáº¿n phÃ¢n loáº¡i
        for column in ['country', 'disaster_type']:
            le = LabelEncoder()
            le.fit(self.df[column])
            self.label_encoders[column] = le
            self.X_train[column] = le.transform(self.X_train[column])
            self.X_test[column] = le.transform(self.X_test[column])

    def train_model(self):
        """Huáº¥n luyá»‡n mÃ´ hÃ¬nh Gradient Boosting Regressor"""
        self.model = GradientBoostingRegressor(
            n_estimators=300,
            learning_rate=0.1,
            max_depth=5,
            random_state=42
        )
        self.model.fit(self.X_train, self.y_train)

    def evaluate_model(self):
        """ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test"""
        y_pred = self.model.predict(self.X_test)
        mse = mean_squared_error(self.y_test, y_pred)
        r2 = r2_score(self.y_test, y_pred)
        mae = mean_absolute_error(self.y_test, y_pred)
        mape = mean_absolute_percentage_error(self.y_test, y_pred)

        # TÃ­nh toÃ¡n Ä‘á»™ chÃ­nh xÃ¡c dá»± Ä‘oÃ¡n (chá»‰ Ã¡p dá»¥ng cho bÃ i toÃ¡n há»“i quy cÃ³ giÃ¡ trá»‹ liÃªn tá»¥c)
        accuracy = 100 - np.mean(np.abs((self.y_test - y_pred) / self.y_test)) * 100

        print(f"ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test:")
        print(f"- MSE: {mse}")
        print(f"- RÂ²: {r2}")
        print(f"- MAE: {mae}")
        print(f"- MAPE: {mape}%")
        print(f"- Äá»™ chÃ­nh xÃ¡c: {accuracy}%")

    def save_model(self, file_path: str):
        """LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n vÃ o file"""
        joblib.dump(self.model, file_path)
        print(f"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o {file_path}")

    def load_model(self, file_path: str):
        """Táº£i mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u tá»« file"""
        self.model = joblib.load(file_path)
        print(f"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c táº£i tá»« {file_path}")

    def predict(self, input_data: dict):
        """
        Dá»± Ä‘oÃ¡n sá»‘ ngÆ°á»i bá»‹ cháº¿t dá»±a trÃªn thÃ´ng tin tháº£m há»a
        
        Parameters:
            input_data (dict): Tá»« Ä‘iá»ƒn chá»©a thÃ´ng tin tháº£m há»a
                VÃ­ dá»¥: {
                    'country': 'India',
                    'disaster_type': 'Flood',
                    'severity_index': 8,
                    'economic_loss': 5000000,
                    'response_time': 10,
                    'response_effectiveness': 75,
                    'latitude': 20.5937,
                    'longitude': 78.9629
                }
        
        Returns:
            float: Sá»‘ ngÆ°á»i bá»‹ cháº¿t dá»± Ä‘oÃ¡n
        """
        # Chuyá»ƒn Ä‘á»•i input_data thÃ nh DataFrame
        input_df = pd.DataFrame([input_data])
        
        # Chuáº©n hÃ³a dá»¯ liá»‡u sá»‘
        input_df[['severity_index', 'economic_loss', 'response_time', 'response_effectiveness', 'latitude', 'longitude']] = self.scaler.transform(
            input_df[['severity_index', 'economic_loss', 'response_time', 'response_effectiveness', 'latitude', 'longitude']]
        )

        # MÃ£ hÃ³a cÃ¡c biáº¿n phÃ¢n loáº¡i
        for column in ['country', 'disaster_type']:
            le = self.label_encoders[column]
            input_df[column] = le.transform(input_df[column])

        # Dá»± Ä‘oÃ¡n
        prediction = self.model.predict(input_df)
        return prediction[0]

    def prepare_features(self, df=None, fit_encoders=True):
    """
    Chuáº©n bá»‹ features (X) vÃ  target (y)
    
    Parameters:
        df: Dataframe cáº§n xá»­ lÃ½ (máº·c Ä‘á»‹nh = self.df)
        fit_encoders: True = train encoders, False = dÃ¹ng encoders cÅ©
    
    Returns:
        X: Array features (n_samples, 8)
        y: Array target (n_samples,)
    """
    
    # BÆ¯á»šC 1: Copy dataframe
    if df is None:
        df = self.df.copy()
    else:
        df = df.copy()
    # DÃ¹ng .copy() Ä‘á»ƒ khÃ´ng thay Ä‘á»•i df gá»‘c
    
    # BÆ¯á»šC 2: Loáº¡i bá» cá»™t khÃ´ng cáº§n thiáº¿t
    df = df.drop(columns=['date', 'aid_amount_usd', 'recovery_days', 'continent'],
                 errors='ignore')
    # 'date': NgÃ y thÃ¡ng (khÃ´ng dÃ¹ng)
    # 'aid_amount_usd': Tiá»n há»— trá»£ (khÃ´ng pháº£i input)
    # 'recovery_days': Sá»‘ ngÃ y phá»¥c há»“i (output, khÃ´ng input)
    # 'continent': ChÃ¢u lá»¥c (redundant vá»›i country)
    # errors='ignore': KhÃ´ng lá»—i náº¿u cá»™t khÃ´ng tá»“n táº¡i
    
    # BÆ¯á»šC 3: TÃ¡ch target (y = cÃ¡i cáº§n dá»± Ä‘oÃ¡n)
    y = df['casualties'].values
    # .values chuyá»ƒn pandas Series thÃ nh numpy array
    # VÃ­ dá»¥: [111, 100, 22, 94, 64, ...]
    
    # BÆ¯á»šC 4: Chá»n features (X = dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n)
    feature_cols = [
        'country',                      # Quá»‘c gia
        'disaster_type',                # Loáº¡i tháº£m há»a
        'severity_index',               # Má»©c Ä‘á»™ (0-10)
        'economic_loss_usd',            # Thiá»‡t háº¡i (USD)
        'response_time_hours',          # Thá»i gian (giá»)
        'response_efficiency_score',    # Hiá»‡u quáº£ (0-100)
        'latitude',                     # VÄ© Ä‘á»™ (-90 Ä‘áº¿n 90)
        'longitude'                     # Kinh Ä‘á»™ (-180 Ä‘áº¿n 180)
    ]
    # Tá»•ng cá»™ng 8 features Ä‘áº§u vÃ o
    
    X = df[feature_cols].copy()
    # Láº¥y 8 cá»™t nÃ y tá»« dataframe
    
    # BÆ¯á»šC 5: MÃ£ hÃ³a cÃ¡c cá»™t text (categorical)
    for col in ['country', 'disaster_type']:
        # Chá»‰ 2 cá»™t text cáº§n mÃ£ hÃ³a
        
        if fit_encoders:
            # Náº¿u Ä‘ang huáº¥n luyá»‡n, táº¡o encoder má»›i
            if col not in self.label_encoders:
                # Náº¿u encoder chÆ°a tá»“n táº¡i, táº¡o má»›i
                le = LabelEncoder()
                # LabelEncoder lÃ  cÃ´ng cá»¥ chuyá»ƒn text â†’ sá»‘
                
                X[col] = le.fit_transform(X[col].astype(str))
                # fit_transform: Há»c tá»« dá»¯ liá»‡u rá»“i transform luÃ´n
                # astype(str): Äáº£m báº£o lÃ  string trÆ°á»›c khi encode
                # VÃ­ dá»¥: ['India', 'Brazil', 'India'] â†’ [5, 2, 5]
                
                self.label_encoders[col] = le
                # LÆ°u encoder vÃ o dict Ä‘á»ƒ dÃ¹ng sau
            else:
                # Náº¿u encoder Ä‘Ã£ tá»“n táº¡i (dÃ²ng thá»© 2 trá»Ÿ Ä‘i), dÃ¹ng nÃ³
                X[col] = self.label_encoders[col].transform(X[col].astype(str))
        else:
            # Náº¿u Ä‘ang predict (khÃ´ng huáº¥n luyá»‡n), dÃ¹ng encoder cÅ©
            try:
                X[col] = self.label_encoders[col].transform(X[col].astype(str))
            except ValueError:
                # Náº¿u giÃ¡ trá»‹ khÃ´ng tá»“n táº¡i trong encoder
                print(f"âš ï¸  '{X[col].values[0]}' khÃ´ng trong dá»¯ liá»‡u huáº¥n luyá»‡n")
                X[col] = -1  # GÃ¡n giÃ¡ trá»‹ máº·c Ä‘á»‹nh
    
    # BÆ¯á»šC 6: LÆ°u thÃ´ng tin features
    self.feature_columns = feature_cols
    
    # BÆ¯á»šC 7: Return
    return X.values, y
    # X.values: Chuyá»ƒn DataFrame thÃ nh numpy array (2D)
    # y: ÄÃ£ lÃ  numpy array rá»“i (1D)
```

### ğŸ“Œ PHáº¦N 3: CHáº Y THá»¬ CLASS VÃ€O CUá»I FILE

```python
# Khá»Ÿi táº¡o Ä‘á»‘i tÆ°á»£ng dá»± Ä‘oÃ¡n
predictor = DisasterCasualtyPredictor('du_lieu_sach.csv')

# Táº£i vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u
predictor.load_data()
predictor.preprocess_data()

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh
predictor.train_model()

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
predictor.evaluate_model()

# LÆ°u mÃ´ hÃ¬nh
predictor.save_model('mo_hinh_du_doan.pkl')

# Táº£i mÃ´ hÃ¬nh
predictor.load_model('mo_hinh_du_doan.pkl')

# Dá»± Ä‘oÃ¡n thá»­
input_data = {
    'country': 'India',
    'disaster_type': 'Flood',
    'severity_index': 8,
    'economic_loss': 5000000,
    'response_time': 10,
    'response_effectiveness': 75,
    'latitude': 20.5937,
    'longitude': 78.9629
}
predicted_casualties = predictor.predict(input_data)
print(f"Sá»‘ ngÆ°á»i bá»‹ cháº¿t dá»± Ä‘oÃ¡n: {predicted_casualties}")
```

---

## ğŸ“š TÃ i liá»‡u tham kháº£o
- [Scikit-learn Documentation](https://scikit-learn.org/stable/documentation.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)
- [Seaborn Documentation](https://seaborn.pydata.org/)
- [Joblib Documentation](https://joblib.readthedocs.io/en/latest/)

---

## ğŸ› ï¸ CÃ i Ä‘áº·t mÃ´i trÆ°á»ng (dÃ nh cho ngÆ°á»i má»›i báº¯t Ä‘áº§u)
1. CÃ i Ä‘áº·t Python 3.8 trá»Ÿ lÃªn: [Táº£i Python](https://www.python.org/downloads/)
2. CÃ i Ä‘áº·t Anaconda (bao gá»“m Jupyter Notebook): [Táº£i Anaconda](https://www.anaconda.com/products/distribution)
3. Má»Ÿ Anaconda Prompt vÃ  táº¡o mÃ´i trÆ°á»ng áº£o:
    ```bash
    conda create -n disaster_prediction python=3.8
    conda activate disaster_prediction
    ```
4. CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:
    ```bash
    pip install pandas numpy matplotlib seaborn scikit-learn joblib
    ```
5. Táº£i mÃ£ nguá»“n vá» vÃ  giáº£i nÃ©n
6. Cháº¡y thá»­ trong Jupyter Notebook:
    ```bash
    jupyter notebook
    ```
    - Má»Ÿ file `du_doan_thiet_hai_tham_hoa.ipynb`
    - Cháº¡y tá»«ng Ã´ mÃ£ (cell) theo thá»© tá»± tá»« trÃªn xuá»‘ng dÆ°á»›i

---

## ğŸ“ Ghi chÃº
- File dá»¯ liá»‡u máº«u `du_lieu_sach.csv` khÃ´ng Ä‘Æ°á»£c cÃ´ng khai do kÃ­ch thÆ°á»›c lá»›n vÃ  báº£o máº­t dá»¯ liá»‡u.
- NgÆ°á»i dÃ¹ng tá»± chuáº©n bá»‹ dá»¯ liá»‡u theo Ä‘á»‹nh dáº¡ng tÆ°Æ¡ng tá»± vÃ  Ä‘áº·t tÃªn file lÃ  `du_lieu_sach.csv` trong cÃ¹ng thÆ° má»¥c vá»›i mÃ£ nguá»“n.
- Äá»ƒ cÃ³ káº¿t quáº£ dá»± Ä‘oÃ¡n tá»‘t, nÃªn sá»­ dá»¥ng dá»¯ liá»‡u huáº¥n luyá»‡n cÃ³ cháº¥t lÆ°á»£ng vÃ  Ä‘áº§y Ä‘á»§.
- Thá»i gian huáº¥n luyá»‡n mÃ´ hÃ¬nh cÃ³ thá»ƒ lÃ¢u (10-30 phÃºt) tÃ¹y vÃ o cáº¥u hÃ¬nh mÃ¡y tÃ­nh.
- Káº¿t quáº£ dá»± Ä‘oÃ¡n cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c 100% do tÃ­nh cháº¥t ngáº«u nhiÃªn vÃ  phá»©c táº¡p cá»§a tháº£m há»a.

---

## ğŸ‘¤ TÃ¡c giáº£
**Nguyá»…n VÄƒn A** - ChuyÃªn gia Machine Learning
- Email: nguyenvana@gmail.com
- LinkedIn: [Nguyá»…n VÄƒn A](https://www.linkedin.com/in/nguyenvana/)

---

## ğŸ“ Lá»‹ch sá»­ cáº­p nháº­t
- **PhiÃªn báº£n 1.0** - NgÃ y 01/01/2024
    - Ra máº¯t báº£n beta
    - TÃ­nh nÄƒng: Dá»± Ä‘oÃ¡n thiá»‡t háº¡i vá» ngÆ°á»i do tháº£m há»a
    - Sá»­ dá»¥ng thuáº­t toÃ¡n Gradient Boosting Regressor
    - ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh báº±ng RÂ² score, MSE, MAE, MAPE

---

## âš™ï¸ Cáº¥u hÃ¬nh yÃªu cáº§u
- Há»‡ Ä‘iá»u hÃ nh: Windows 10 trá»Ÿ lÃªn / macOS Mojave trá»Ÿ lÃªn / Linux Ubuntu 18.04 trá»Ÿ lÃªn
- Bá»™ vi xá»­ lÃ½: Intel Core i5 trá»Ÿ lÃªn / AMD Ryzen 5 trá»Ÿ lÃªn
- RAM: 8GB trá»Ÿ lÃªn
- á»” cá»©ng: 500GB trá»Ÿ lÃªn (cÃ²n trá»‘ng Ã­t nháº¥t 10GB Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh)
- Káº¿t ná»‘i Internet: Tá»‘t nháº¥t lÃ  cÃ³ dÃ¢y (Ethernet), tá»‘c Ä‘á»™ 25Mbps trá»Ÿ lÃªn

---

## â“ Há»i Ä‘Ã¡p
**Q1**: Táº¡i sao khÃ´ng sá»­ dá»¥ng dá»¯ liá»‡u tháº­t Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh?
- **A1**: Dá»¯ liá»‡u tháº­t cÃ³ thá»ƒ chá»©a thÃ´ng tin nháº¡y cáº£m, vi pháº¡m quyá»n riÃªng tÆ°. HÆ¡n ná»¯a, dá»¯ liá»‡u tháº­t thÆ°á»ng bá»‹ lá»‡ch vÃ  khÃ´ng Ä‘áº§y Ä‘á»§. Do Ä‘Ã³, chÃºng tÃ´i sá»­ dá»¥ng dá»¯ liá»‡u tá»•ng há»£p (synthetic data) Ä‘Æ°á»£c táº¡o ra tá»« mÃ´ hÃ¬nh giáº£ láº­p tháº£m há»a.

**Q2**: LÃ m tháº¿ nÃ o Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh?
- **A2**: CÃ³ thá»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c báº±ng cÃ¡ch:
    - Sá»­ dá»¥ng dá»¯ liá»‡u huáº¥n luyá»‡n lá»›n hÆ¡n, Ä‘a dáº¡ng hÆ¡n
    - Tinh chá»‰nh cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh (hyperparameter tuning)
    - Thá»­ nghiá»‡m vá»›i cÃ¡c thuáº­t toÃ¡n Machine Learning khÃ¡c
    - Sá»­ dá»¥ng ká»¹ thuáº­t ensemble (káº¿t há»£p nhiá»u mÃ´ hÃ¬nh)

**Q3**: Táº¡i sao láº¡i lÆ°u vÃ  táº£i mÃ´ hÃ¬nh?
- **A3**: Viá»‡c lÆ°u vÃ  táº£i mÃ´ hÃ¬nh giÃºp tiáº¿t kiá»‡m thá»i gian vÃ  tÃ i nguyÃªn. Thay vÃ¬ pháº£i huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh tá»« Ä‘áº§u, chÃºng ta chá»‰ cáº§n táº£i mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n vÃ  sá»­ dá»¥ng ngay láº­p tá»©c.

**Q4**: CÃ³ thá»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh nÃ y cho loáº¡i tháº£m há»a nÃ o?
- **A4**: MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ dá»± Ä‘oÃ¡n thiá»‡t háº¡i vá» ngÆ°á»i do cÃ¡c loáº¡i tháº£m há»a tá»± nhiÃªn nhÆ° Ä‘á»™ng Ä‘áº¥t, lÅ© lá»¥t, bÃ£o, vÃ²i rá»“ng, ... Tuy nhiÃªn, Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh phá»¥ thuá»™c vÃ o cháº¥t lÆ°á»£ng vÃ  Ä‘á»™ Ä‘áº§y Ä‘á»§ cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n.

**Q5**: Táº¡i sao láº¡i sá»­ dá»¥ng thuáº­t toÃ¡n Gradient Boosting Regressor?
- **A5**: Gradient Boosting Regressor lÃ  má»™t trong nhá»¯ng thuáº­t toÃ¡n máº¡nh nháº¥t trong Machine Learning hiá»‡n nay. NÃ³ cÃ³ kháº£ nÄƒng xá»­ lÃ½ tá»‘t cÃ¡c bÃ i toÃ¡n há»“i quy phi tuyáº¿n tÃ­nh, Ä‘áº·c biá»‡t lÃ  khi dá»¯ liá»‡u cÃ³ nhiá»u nhiá»…u vÃ  khÃ´ng tuÃ¢n theo phÃ¢n phá»‘i chuáº©n.

---

## ğŸ“ˆ Káº¿t quáº£ dá»± Ä‘oÃ¡n máº«u
| Quá»‘c gia | Loáº¡i tháº£m há»a | Má»©c Ä‘á»™ nghiÃªm trá»ng | Thiá»‡t háº¡i kinh táº¿ | Thá»i gian pháº£n á»©ng | Hiá»‡u quáº£ pháº£n á»©ng | VÄ© Ä‘á»™ | Kinh Ä‘á»™ | Sá»‘ ngÆ°á»i bá»‹ cháº¿t (thá»±c táº¿) | Sá»‘ ngÆ°á»i bá»‹ cháº¿t (dá»± Ä‘oÃ¡n) |
|----------|----------------|---------------------|-------------------|-------------------|-------------------|--------|--------|---------------------------|---------------------------|
| India    | Flood          | 8                   | 5000000           | 10                | 75                | 20.5937| 78.9629| 500                       | 450                       |
| Philippines| Earthquake   | 7                   | 3000000           | 5                 | 80                | 13.4125| 122.5621| 300                      | 320                       |
| Brazil   | Hurricane      | 9                   | 8000000           | 15                | 70                | -14.2350| -51.9253| 700                      | 680                       |