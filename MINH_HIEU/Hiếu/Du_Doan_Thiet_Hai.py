"""
D·ª± ƒëo√°n thi·ªát h·∫°i v·ªÅ ng∆∞·ªùi do th·∫£m h·ªça g√¢y ra
Input: Qu·ªëc gia, th·∫£m h·ªça, m·ª©c ƒë·ªô nghi√™m tr·ªçng, thi·ªát h·∫°i kinh t·∫ø, 
       th·ªùi gian ph·∫£n ·ª©ng, hi·ªáu qu·∫£ ph·∫£n ·ª©ng, kinh ƒë·ªô, vƒ© ƒë·ªô
Output: S·ªë ng∆∞·ªùi b·ªã ch·∫øt do th·∫£m h·ªça
"""

import os
import pandas as pd
import numpy as np

# L·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a file Python n√†y
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
DEFAULT_CSV = os.path.join(SCRIPT_DIR, "global_disaster_response_2018_2024.csv")
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
import warnings

warnings.filterwarnings('ignore')


class DisasterCasualtyPredictor:
    """M√¥ h√¨nh d·ª± ƒëo√°n s·ªë ng∆∞·ªùi b·ªã ch·∫øt do th·∫£m h·ªça"""
    
    def __init__(self, csv_path: str):
        """
        Kh·ªüi t·∫°o m√¥ h√¨nh
        
        Parameters
        ----------
        csv_path : str
            ƒê∆∞·ªùng d·∫´n file CSV ch·ª©a d·ªØ li·ªáu hu·∫•n luy·ªán
        """
        self.csv_path = csv_path
        self.df = None
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.feature_columns = None
        
    def load_data(self):
        """Load v√† x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ CSV"""
        print("ƒêang t·∫£i d·ªØ li·ªáu...")
        self.df = pd.read_csv(self.csv_path)
        
        print(f" T·∫£i th√†nh c√¥ng {len(self.df)} b·∫£n ghi")
        print(f"C√°c c·ªôt: {list(self.df.columns)}")
        print(f"\nTh·ªëng k√™ d·ªØ li·ªáu Casualties:")
        print(f"  Min: {self.df['casualties'].min():.0f}")
        print(f"  Max: {self.df['casualties'].max():.0f}")
        print(f"  Mean: {self.df['casualties'].mean():.0f}")
        print(f"  Median: {self.df['casualties'].median():.0f}")
        
        return self.df
    
    def prepare_features(self, df=None):
        """
        Chu·∫©n b·ªã features cho m√¥ h√¨nh
        
        Parameters
        ----------
        df : pd.DataFrame, optional
            DataFrame ƒë·ªÉ x·ª≠ l√Ω. N·∫øu None, d√πng self.df
            
        Returns
        -------
        X : np.ndarray
            Features ƒë√£ x·ª≠ l√Ω
        y : np.ndarray
            Target (casualties)
        """
        if df is None:
            df = self.df.copy()
        else:
            df = df.copy()
        
        # X√≥a c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt
        df = df.drop(columns=['date', 'aid_amount_usd', 'recovery_days', 'continent'], 
                     errors='ignore')
        
        # T√°ch target
        y = df['casualties'].values
        
        # Features: qu·ªëc gia, lo·∫°i th·∫£m h·ªça, m·ª©c ƒë·ªô, thi·ªát h·∫°i kinh t·∫ø, 
        #          th·ªùi gian ph·∫£n ·ª©ng, hi·ªáu qu·∫£ ph·∫£n ·ª©ng, kinh ƒë·ªô, vƒ© ƒë·ªô
        feature_cols = ['country', 'disaster_type', 'severity_index', 'economic_loss_usd',
                       'response_time_hours', 'response_efficiency_score', 
                       'latitude', 'longitude']
        
        X = df[feature_cols].copy()
        
        # Encode c√°c c·ªôt categorical
        for col in ['country', 'disaster_type']:
            if col not in self.label_encoders:
                self.label_encoders[col] = LabelEncoder()
                X[col] = self.label_encoders[col].fit_transform(X[col].astype(str))
            else:
                X[col] = self.label_encoders[col].transform(X[col].astype(str))
        
        self.feature_columns = feature_cols
        
        return X.values, y
    
    def train(self, test_size=0.2, random_state=42):
        """
        Hu·∫•n luy·ªán m√¥ h√¨nh
        
        Parameters
        ----------
        test_size : float
            T·ª∑ l·ªá chia test set
        random_state : int
            Random seed
        """
        print("\nüîß ƒêang chu·∫©n b·ªã d·ªØ li·ªáu...")
        X, y = self.prepare_features()
        
        # Chia d·ªØ li·ªáu
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        print(f"   Train size: {len(X_train)}, Test size: {len(X_test)}")
        
        # Chu·∫©n h√≥a features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Hu·∫•n luy·ªán m√¥ h√¨nh Gradient Boosting
        print("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh Gradient Boosting...")
        self.model = GradientBoostingRegressor(
            n_estimators=200,
            learning_rate=0.1,
            max_depth=5,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=random_state,
            verbose=0
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # ƒê√°nh gi√° m√¥ h√¨nh
        y_pred_train = self.model.predict(X_train_scaled)
        y_pred_test = self.model.predict(X_test_scaled)
        
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        train_mae = mean_absolute_error(y_train, y_pred_train)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        
        print(f"\nK·∫øt qu·∫£ ƒë√°nh gi√°:")
        print(f"  Train R¬≤ Score: {train_r2:.4f}")
        print(f"  Test R¬≤ Score: {test_r2:.4f}")
        print(f"  Train RMSE: {train_rmse:.2f}")
        print(f"  Test RMSE: {test_rmse:.2f}")
        print(f"  Train MAE: {train_mae:.2f}")
        print(f"  Test MAE: {test_mae:.2f}")
        
        # Feature importance
        print(f"\nT·∫ßm quan tr·ªçng c·ªßa features:")
        feature_importance = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        for idx, row in feature_importance.iterrows():
            print(f"  {row['feature']:30s}: {row['importance']:.4f}")
        
        return {
            'train_r2': train_r2,
            'test_r2': test_r2,
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'train_mae': train_mae,
            'test_mae': test_mae
        }
    
    def predict(self, country: str, disaster_type: str, severity_index: float,
                economic_loss_usd: float, response_time_hours: float,
                response_efficiency_score: float, latitude: float, 
                longitude: float) -> float:
        """
        D·ª± ƒëo√°n s·ªë ng∆∞·ªùi b·ªã ch·∫øt
        
        Parameters
        ----------
        country : str
            Qu·ªëc gia
        disaster_type : str
            Lo·∫°i th·∫£m h·ªça
        severity_index : float
            M·ª©c ƒë·ªô nghi√™m tr·ªçng (0-10)
        economic_loss_usd : float
            Thi·ªát h·∫°i kinh t·∫ø (USD)
        response_time_hours : float
            Th·ªùi gian ph·∫£n ·ª©ng (gi·ªù)
        response_efficiency_score : float
            ƒêi·ªÉm hi·ªáu qu·∫£ ph·∫£n ·ª©ng (0-100)
        latitude : float
            Vƒ© ƒë·ªô
        longitude : float
            Kinh ƒë·ªô
            
        Returns
        -------
        float
            D·ª± ƒëo√°n s·ªë ng∆∞·ªùi b·ªã ch·∫øt
        """
        if self.model is None:
            raise ValueError("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. G·ªçi train() tr∆∞·ªõc.")
        
        # Chu·∫©n b·ªã input
        input_data = pd.DataFrame({
            'country': [country],
            'disaster_type': [disaster_type],
            'severity_index': [severity_index],
            'economic_loss_usd': [economic_loss_usd],
            'response_time_hours': [response_time_hours],
            'response_efficiency_score': [response_efficiency_score],
            'latitude': [latitude],
            'longitude': [longitude]
        })
        
        # Encode categorical features
        for col in ['country', 'disaster_type']:
            try:
                input_data[col] = self.label_encoders[col].transform(
                    input_data[col].astype(str)
                )
            except ValueError:
                print(f"  {col} '{input_data[col].values[0]}' kh√¥ng trong d·ªØ li·ªáu hu·∫•n luy·ªán")
                input_data[col] = 0
        
        # Chu·∫©n h√≥a
        input_scaled = self.scaler.transform(input_data)
        
        # D·ª± ƒëo√°n
        prediction = self.model.predict(input_scaled)[0]
        
        return max(0, prediction)
    
    def save_model(self, filepath: str):
        """L∆∞u m√¥ h√¨nh"""
        joblib.dump({
            'model': self.model,
            'scaler': self.scaler,
            'label_encoders': self.label_encoders,
            'feature_columns': self.feature_columns
        }, filepath)
        print(f"M√¥ h√¨nh ƒë√£ l∆∞u t·∫°i {filepath}")
    
    def load_model(self, filepath: str):
        """Load m√¥ h√¨nh t·ª´ file"""
        data = joblib.load(filepath)
        self.model = data['model']
        self.scaler = data['scaler']
        self.label_encoders = data['label_encoders']
        self.feature_columns = data['feature_columns']
        print(f"M√¥ h√¨nh ƒë√£ load t·ª´ {filepath}")


def interactive_prediction(csv_path=None):
    """D·ª± ƒëo√°n t∆∞∆°ng t√°c t·ª´ input c·ªßa ng∆∞·ªùi d√πng"""
    if csv_path is None:
        csv_path = DEFAULT_CSV
    print("\n" + "="*70)
    print("CH·∫æ ƒê·ªò D·ª∞ ƒêO√ÅN T∆Ø∆†NG T√ÅC")
    print("="*70)
    
    predictor = DisasterCasualtyPredictor(csv_path)
    predictor.load_data()
    predictor.train()
    
    # L·∫•y danh s√°ch qu·ªëc gia v√† th·∫£m h·ªça t·ª´ d·ªØ li·ªáu
    countries = sorted(predictor.df['country'].unique())
    disaster_types = sorted(predictor.df['disaster_type'].unique())
    
    print(f"\nC√°c qu·ªëc gia trong d·ªØ li·ªáu:")
    for i, country in enumerate(countries, 1):
        print(f"   {i}. {country}")
    
    print(f"\nC√°c lo·∫°i th·∫£m h·ªça:")
    for i, dtype in enumerate(disaster_types, 1):
        print(f"   {i}. {dtype}")
    
    while True:
        print("\n" + "-"*70)
        
        try:
            country = input("Nh·∫≠p qu·ªëc gia (ho·∫∑c 'quit' ƒë·ªÉ tho√°t): ").strip()
            if country.lower() == 'quit':
                break
            
            disaster_type = input("Nh·∫≠p lo·∫°i th·∫£m h·ªça: ").strip()
            severity_index = float(input("Nh·∫≠p m·ª©c ƒë·ªô nghi√™m tr·ªçng (0-10): "))
            economic_loss = float(input("Nh·∫≠p thi·ªát h·∫°i kinh t·∫ø (USD): "))
            response_time = float(input("Nh·∫≠p th·ªùi gian ph·∫£n ·ª©ng (gi·ªù): "))
            efficiency = float(input("Nh·∫≠p hi·ªáu qu·∫£ ph·∫£n ·ª©ng (0-100): "))
            latitude = float(input("Nh·∫≠p vƒ© ƒë·ªô: "))
            longitude = float(input("Nh·∫≠p kinh ƒë·ªô: "))
            
            prediction = predictor.predict(
                country=country,
                disaster_type=disaster_type,
                severity_index=severity_index,
                economic_loss_usd=economic_loss,
                response_time_hours=response_time,
                response_efficiency_score=efficiency,
                latitude=latitude,
                longitude=longitude
            )
            
            print("\n" + "="*70)
            print(f"K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN")
            print("="*70)
            print(f"  Qu·ªëc gia: {country}")
            print(f"  Th·∫£m h·ªça: {disaster_type}")
            print(f"  M·ª©c ƒë·ªô: {severity_index}/10")
            print(f"  Thi·ªát h·∫°i kinh t·∫ø: ${economic_loss:,.0f}")
            print(f"  Th·ªùi gian ph·∫£n ·ª©ng: {response_time} gi·ªù")
            print(f"  Hi·ªáu qu·∫£: {efficiency}/100")
            print(f"  V·ªã tr√≠: ({latitude}, {longitude})")
            print("-"*70)
            print(f"D·ª∞ ƒêO√ÅN S·ªê NG∆Ø·ªúI B·ªä CH·∫æT: {prediction:.0f} ng∆∞·ªùi")
            print("="*70)
            
        except ValueError:
            print(f"L·ªói: Vui l√≤ng nh·∫≠p d·ªØ li·ªáu h·ª£p l·ªá!")
        except Exception as e:
            print(f"L·ªói: {str(e)}")


def test_predictions(csv_path=None):
    """Test d·ª± ƒëo√°n v·ªõi m·ªôt s·ªë tr∆∞·ªùng h·ª£p"""
    if csv_path is None:
        csv_path = DEFAULT_CSV
    
    predictor = DisasterCasualtyPredictor(csv_path)
    
    # Load d·ªØ li·ªáu
    predictor.load_data()
    
    # Hu·∫•n luy·ªán m√¥ h√¨nh
    predictor.train()
    
    # L∆∞u m√¥ h√¨nh
    predictor.save_model("disaster_casualty_model.pkl")
    
    # Test d·ª± ƒëo√°n v·ªõi m·ªôt s·ªë tr∆∞·ªùng h·ª£p
    print("\n" + "="*70)
    print("TEST D·ª∞ ƒêO√ÅN V·ªöI C√ÅC TR∆Ø·ªúNG H·ª¢P M·∫™U")
    print("="*70)
    
    test_cases = [
        {
            'country': 'India',
            'disaster_type': 'Earthquake',
            'severity_index': 8.0,
            'economic_loss_usd': 5000000,
            'response_time_hours': 12,
            'response_efficiency_score': 85,
            'latitude': 28.7,
            'longitude': 77.2,
            'description': 'ƒê·ªông ƒë·∫•t m·∫°nh t·∫°i ·∫§n ƒê·ªô'
        },
        {
            'country': 'Philippines',
            'disaster_type': 'Flood',
            'severity_index': 7.5,
            'economic_loss_usd': 3000000,
            'response_time_hours': 8,
            'response_efficiency_score': 90,
            'latitude': 14.5,
            'longitude': 121.0,
            'description': 'L≈© l·ª•t ·ªü Philippines'
        },
        {
            'country': 'Brazil',
            'disaster_type': 'Wildfire',
            'severity_index': 6.5,
            'economic_loss_usd': 2000000,
            'response_time_hours': 16,
            'response_efficiency_score': 75,
            'latitude': -23.55,
            'longitude': -46.6,
            'description': 'Ch√°y r·ª´ng ·ªü Brazil'
        },
        {
            'country': 'Japan',
            'disaster_type': 'Earthquake',
            'severity_index': 9.0,
            'economic_loss_usd': 8000000,
            'response_time_hours': 2,
            'response_efficiency_score': 95,
            'latitude': 35.6762,
            'longitude': 139.6503,
            'description': 'ƒê·ªông ƒë·∫•t c·ª±c m·∫°nh t·∫°i Nh·∫≠t B·∫£n'
        },
        {
            'country': 'United States',
            'disaster_type': 'Hurricane',
            'severity_index': 8.5,
            'economic_loss_usd': 10000000,
            'response_time_hours': 6,
            'response_efficiency_score': 88,
            'latitude': 29.9511,
            'longitude': -90.2623,
            'description': 'B√£o t·∫•n c√¥ng New Orleans'
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        desc = case.pop('description')
        prediction = predictor.predict(**case)
        
        print(f"\nTr∆∞·ªùng h·ª£p {i}: {desc}")
        print(f"  Qu·ªëc gia: {case['country']}")
        print(f"  Th·∫£m h·ªça: {case['disaster_type']}")
        print(f"  M·ª©c ƒë·ªô: {case['severity_index']}/10")
        print(f"  Thi·ªát h·∫°i: ${case['economic_loss_usd']:,.0f}")
        print(f"  Th·ªùi gian ph·∫£n ·ª©ng: {case['response_time_hours']} gi·ªù")
        print(f"  Hi·ªáu qu·∫£: {case['response_efficiency_score']}/100")
        print(f"  V·ªã tr√≠: ({case['latitude']}, {case['longitude']})")
        print(f"  D·ª∞ ƒêO√ÅN S·ªê NG∆Ø·ªúI B·ªä CH·∫æT: {prediction:.0f} ng∆∞·ªùi")


def main():
    """Main function"""
    
    print("\n" + "="*70)
    print("H·ªÜ TH·ªêNG D·ª∞ ƒêO√ÅN THI·ªÜT H·∫†I NG∆Ø·ªúI DO TH·∫¢M H·ªåA")
    print("="*70)
    print("\nCh·ªçn ch·∫ø ƒë·ªô:")
    print("1. Test v·ªõi c√°c tr∆∞·ªùng h·ª£p m·∫´u")
    print("2. D·ª± ƒëo√°n t∆∞∆°ng t√°c (nh·∫≠p d·ªØ li·ªáu t·ª´ b√†n ph√≠m)")
    print("3. Tho√°t")
    
    choice = input("\nNh·∫≠p l·ª±a ch·ªçn (1/2/3): ").strip()
    
    if choice == '1':
        test_predictions()
    elif choice == '2':
        interactive_prediction()
    else:
        print("T·∫°m bi·ªát!")


if __name__ == "__main__":
    # Ch·∫°y test tr·ª±c ti·∫øp ƒë·ªÉ ki·ªÉm tra
    test_predictions()